{
  "hash": "8fef0565c86f65d7d6e2748323db8851",
  "result": {
    "markdown": "---\ntitle: \"Do You Have a Good Reason to Ignore Uncertainty? Check if I Approve of Your Reason Below\"\nauthor: \"Harriet Mason\"\ndate: \"2023-02-25T00:00:00Z\"\nlastMod: \"2023-02-25T00:00:00Z\"\nimage: feature.jpeg\nbibliography: references.bib\ncategories:\n  - data visualisation\n  - statistics\ntags:\n  - data visualisation\n  - statistics\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# The Wombat Conference\n\nRecently I went to a conference with the central topic of visualising\ndata. The conference was great and it was the first time i have ever\nbeen able to understand most of most of the speeches. Usually I just\nstare at the speaker's slides and wonder if I am the only one who has no\nidea what they are talking about. There was one overwhelming sentiment\nshared by all the speakers that seemed a little disastrous to my\nresearch. Speaker after speaker went to the podium, started their\nspeech, and said they didn't visualize uncertainty (except keynote\nspeaker but I was late and missed it). As a PhD student whose research\ncentres on visualising uncertainty, this could be seen as a bit of a\nspanner thrown into my work. I will admit that it became a running joke\nin my notes, to see how long until the speaker either admitted they\ndon't visualise uncertainty, or just outright dismissed it as feasible\nin their work. I started to wonder if living in the woods and carving\nsticks would be a more fruitful career than what I was currently doing.\nI have since spoken about this to multiple friends who have admonished\nthose who openly reject visualising uncertainty, but I actually respect\nthe honesty. In trying to improve uncertainty visualisations, I have\nnoticed that uncertainty is rarely visualised and there must be a reason\nfor it that goes beyond \"the current methods aren't good\". We can all\nsit here and say \"we should visualise uncertainty\" but the reality is,\nnobody actually does and everyone has some reasoning for it that\noutweighs misrepresenting our results. Even if I spend months working on\na new way to visualise uncertainty, without understand why nobody does\nit, my work would be born to live in a frame on my mothers wall, read\nonly by myself and examiners, and used by nobody.\n\n<center>![](wombatfeels.jpeg)</center>\n\n# When to NOT Visualise Uncertainty\n\nWhen I was in high school, my fancy private school paid a lot of money\nto have a speaker come in and talk to my cohort about communicating\nstatistics. To get his point across the speaker gave an example on\nsmoking. His speech went something like this:\n\n\"People are really bad at applying probabilities to themselves,\nespecially when the probability relates to something bad. That means\nthat if the government wants people to stop smoking to decrease the\nburden on the health care system, they can't communicate it through\nprobability. I'm sure that everyone in this room thinks that if you\nsmoke it is certain that you will eventually get cancer and die, that is\nquite frankly not the case. The reality is, even if you smoke you\nactually only have about a 1% chance of getting lung cancer. Obviously\nit also leads to other diseases and a lower quality of life, but it is a\nfar cry away from it being certain you will get cancer and die. The\nreason it is communicated with uncertainty is that we don't want anyone\nto smoke, and we achieve that by communicating with certainty even if it\nis a misrepresentation of reality.\"\n\nAt this point our head of pastoral care interrupted the speaker and\nsays, completely seriously, \"Sorry everyone this man has no idea what he\nis talking about, or he is lying. If you smoke it is certain you will\nget cancer and you will die. There is no probability about it. OK\nbuddy,\" he continues, guesting to the speaker \"keep going\". The speaker\njust stood there shocked for a couple seconds, laughed and then, as\ninstructed, kept going. I imagine he remembered they had already paid\nhim so if they wanted to publicly discredit him and undermine his entire\npoint, it was no skin off his back. I silently wondered if our school\nfees would be cheaper if they just hired whatever nightmare speaker they\nactually wanted. I'm sure some guy who tells students they will go to\nhell if they engage in premarital sex or do drugs would be much cheaper\nthan an expert in communicating statistics, but I digress. This may seem\nirrelevant, but this is a story about how even in a strict context,\npeople don't trust their audience to correctly understand probabilities\nno matter how they are communicated.\n\n<center>![](speakerisdumb.jpeg)</center>\n\nMost people think the reason nobody visualises uncertainty is a lack of\ntrust in peoples ability to understand probability. I do somewhat\nunderstand how people feel when they express this sentiment. I mark\nthird year statistics assignments and only half of the students seem to\nknow what a random variable is. That being said, there is a difference\nbetween However, the conference made it clear that there are many that\npeople avoid visualising uncertainty that are not just to do with\nassuming the worst about the intelligence of your audience. Having now\nread quite a few papers on the topic, finding out why people don't\nexpress the uncertainty in their work is an exercise into insanity.\n\n<center>![](patrickmeme.jpeg)</center>\n\nPrior to reading into it I suspected that the reason authors did not\nvisualise uncertainty was because there were just not enough good and\nintuitive methods. I would be unsurprised if this was a widely held\nbelief. Now that I have read some research one it, I actually think its\njust that people are incentivised not to. The problem is not the\navailable methods or the audience, its human psychology. This is not to\nsay that if someone says current methods are lacking they are always\nmaking up an excuse (for example, visualising uncertainty on maps is very\ndifficult) but it just highly likely that they are. Below I will go\nthough the most common reasons cited for failing to express\nuncertainty, and why they are lacking once you engage in the literature.\nThen you might see what I mean.\n\n# The Excuses (and The Rebuttals)\n\nThere is a large amount of literature providing new ways to visualise\nuncertainty and showing its effectiveness, but much less on why people\ndon't do it. I am going to focus on the reasons provided in \"Why Authors\nDon't Visualize Uncertainty\" by Jessica Hullman because this is one of\nthe few detailed reviews I could find that actually did a structured\ninterview with visualisation authors to find out if they visualised\nuncertainty and why they would chose not to [@Hullman2020a].\n\nThe paper discussed a myriad of reasons provided by the authors to\nexplain why they don't always visualise uncertainty. The most popular\nreasons were: not wanting to overwhelm the audience; an inability to\ncalculate the uncertainty; a lack of access to the uncertainty\ninformation; and not wanting to make their data seem questionable\n[@Hullman2020a]. Bellow I will discuss some more detailed reasons and\ngive my rebuttals to them, however every reason for not expressing\nuncertainty fits into one of these four categories.\n\n<center>![](boxesofexcuses.jpeg)</center>\n\nI want to make it clear that majority of those interviewed or surveyed\nfor Hullman's paper agreed that expressing uncertainty is important and\nshould be done more often [@Hullman2020a]. As a matter of fact, some\npeople agreed that failing to visualize uncertainty is tantamount to\nfraud [@Hullman2020a]. Despite this, only a quarter of respondents\nincluded uncertainty in 50% or more of their visualisations\n[@Hullman2020a]. This means people are convinced that visualising\nuncertainty is important from a moral standpoint, but they have still\nbeen able to provide self sufficient reasoning that allows them to avoid\ndoing it. That doesn't mean the reasoning provided follows consistent\nand sound logic. For example, at least one interviewee from Hullman's\nsurvey claimed that expertise implies that the signal being conveyed is\nsignificant, but also said they would omit uncertainty if it obfuscated\nthe message they were trying to convey [@Hullman2020a]. Even some\nauthors who were capable of calculating and and representing uncertainty\nwell did not do it, and were unable to provide a self-satisfying reason\nwhy. The clear friction in the explanations below are obvious but for\nthe time being I will ignore it and take each claim at face value. At\nthe end I will discuss the clear overarching issue of backward\njustification.\n\n## Authors Don't Want to Overwhelm the Audience\n\nThe common theme among these reasons seems to be a belief that\nuncertainty is secondary to estimations. The argument speaks to an\nunspoken belief of those that work with data, that the uncertainty\nassociated with an estimate (the noise) only exists to hide the estimate\nitself (the signal). From this view, uncertainty is only seen as\nadditional or hindering information, therefore despite its alleged\nimportance, when simplifying a plot uncertainty the first thing to go.\n\n<center>![How I presume visualisation authors see a distribution](estimate.jpeg)</center>\n\nBelow are some examples of these reasonings.\n\n### Clutter\n\n#### Reason\n\nWhen showing a graphic for a short period of time (such as on TV) you\ncan only present one idea per graphic, and uncertainty will clutter the\nvisualisation.\n\n#### Rebuttal\n\nIf you can only show one idea, why not show the uncertainty? For\nexample, something as simple as presenting a range instead of a point\nestimate would give an idea of central location as well as degree of\nuncertainty.\n\nPeople being unable to make quick decision's using uncertainty may not\neven be true. A study that got participants to account for uncertainty\nin bus arrival times showed laypeople have ability to make fast and\naccurate decisions that accounted for uncertainty that was displayed on\na small screen [@Kay2016].\n\n### Audience Understanding\n\n#### Reason\n\nThe general public does not understand randomness so including\nuncertainty will only confuse the audience.\n\n#### Rebuttal\n\nThis statement has two halves that are technically true if you constrain\nit. For example, the statements \"the general public does not have a\n*full and detailed* understanding of the philosophical arguments behind\nuncertainty\" and \"*some* people struggle with uncertainty\" are both\ntrue. What does not seem to be true is the statement above.\n\nFirst, lets address if the general population can understand\nuncertainty. I think blanket yes/no conclusions about whether or not\nuncertainty was understood ignore the intricacies of understanding\nuncertainty that comes through in the research. The general gist seems\nto be this. Can laypeople interpret uncertainty in a way that is\nconsistent with frequentist philosophy? No \\[Hoekstra2014\\]. Can\nlaypeople reliably translate an error bar plot to an equivalent\nhypothesis test? No [@Bella2005]. Can laypeople read an uncertainty plot\nand make accurate and efficient decisions factoring the uncertainty into\ntheir choices? Yes [@Kay2016] [@Fernandes2018]. Additionally, while some\npeople may have a lower baseline than the general public, most people\nget better at understanding uncertainty plots the more they are exposed\nto them [@Kay2016].\n\nRefusing to express uncertainty because people don't understand them,\nprevents people from improving in their ability to understand the plots,\ncausing those that may not be able to understand uncertainty to continue\nto be bad at it.\n\n### Complicates Decision Making\n\n#### Reason\n\nUncertainty confuses people and makes it harder for them to make\ndecisions. Because of cognitive overload we want to be careful about\nconveying important information.\n\n#### Rebuttal\n\nRemoving uncertainty makes the decision making process easier in the\nsame way presenting no choices does. Artificially. Very often there are\nways to simplify other aspects of the design without sacrificing\nuncertainty information.\n\nI think this argument also comes from a misunderstanding of who the\ndecision makers should be in some cases. When presenting evacuation\ninformation and you are worried about confusing a general audience, the\nGovernment may choose to present a simple \"yes or no\" threshold. Here,\nit is not that uncertainty was omitted, but rather the decision maker\nhas been changed.\n\n### Common Knowledge\n\n#### Reason\n\nThe presence of uncertainty is common knowledge and does not need to be\nexplicitly stated. Sometimes I\n\n#### Rebuttal\n\nHow much uncertainty is the actual issue at hand. A vague reference to\nsome uncertainty is quite frankly nonsense. While authors typically\nprefer to express uncertainty in vague terms and will use reasons such\nas the one above to justify it, decision makers prefer uncertainty in\nprecise quantitative terms [@Erev_1990], [@Olson_1997].\n\n### People Don't like it\n\n#### Reason\n\nPeople cannot tolerate uncertainty and it creates negative feelings.\n\n#### Rebuttal\n\nThis is true, however it is not a reason to avoid visualising\nuncertainty.\n\n## Authors Don't Know How to Calculate Uncertainty or Don't have Access to the Information to do so.\n\nThis section is basically a tour of using incompetence to cover up\nlaziness, a fear of being wrong, or a general lack of desire to do\nsomething. I know because I do it. I think the term to describe this\nthat the young socially awake kids use is \"weaponised incompetence\". It\nis when someone pretends to be incompetent so they don't have to do\nthings they don't want to do (such as visualizing uncertainty). The tactic was used by my asshole housemate to avoid unpacking the dishwasher for over a year. Using incompetence as an excuse to not do something doesn't fly too well when you remember, *you can just learn to do the thing you don't know how to do*. If someone genuinely cannot or is anxious about estimating uncertainty in *any* capacity, call me crazy, but I think working with uncertainty was not the best choice of career path.\n\n\n<center>![Actually maybe my housemate was just a huge asshole](housechat.jpeg)</center>\n\n### Multiple Sources of Uncertainty\n\n#### Reason\n\nSometimes there are multiple layers of uncertainty which are too hard to\ncommunicate so it is ignored.\n\n#### Rebuttal\n\nI honestly am happy to take an claim of incompetence in good faith.\nAlso, the details of uncertainty and the assumptions we have to make\naround them can be confusing, so much so that it is the next blog post\ntopic. I don't think this is a good reason to ignore the uncertainty all\ntogether because if something is worth doing, its worth doing badly.\nWhenever I have no idea what I'm doing I just estimate my uncertainty\nwith bootstrapping or assume a normal distribution. I will probably\ncontinue to do this until one of my supervisors reads this post and\ntells me that is bad practice. In which case I will update this to\nreflect whatever they suggest.\n\n### Precision\n\n#### Reason\n\nFear that uncertainty will imply unwarranted precision in estimates\n\n#### Rebuttal \nI think this excuse is interesting because it ignores the\nentire principal of an estimate. An estimate is an effort to put a\nnumber on something uncertain. I suspect that authors see some\nuncertainty visualization, such as confidence intervals, to be a death\nsentence if the actual outcome is outside them. An estimate is a ball\npark, people don't actually expect the true number to be exactly the\nestimate, but people DO expect an outcome to be inside a confidence\ninterval. That is the whole point of them. I haven't suggested a plot in\nany of the other sections, but I think this is the one case where a\nspecific plot could fix the issue. A hypothetical outcome plot never\ngives a firm number on the uncertainty but gives people a \"vibe\" of\npossible outcomes. This way you can express uncertainty without giving\nany precision at all, and in some contexts conveys uncertainty better\nthan other methods [@Kale] [@Hullman2015]. You can even get a version\nthat includes at least one highly disastrous outcome so you don't get\nfired.\n\n## Authors Don't Want Their Work to Seem Questionable\n\nThis sections is basically the \"I'm committing fraud but I have convinced\nmyself that I'm not committing fraud\" section. This makes me think of the\nscene from the Big Short, where Steve Carell's character asks his\ncolleague why real estate agents would openly commit to fraud. His\ncolleague responds by letting him know they are actually bragging.\n\n<center>![](image-1217252454.png)</center>\n\nPersonally, I think people committing fraud and then justifying it with\nsome obvious backwards logic won't be fixed with \"how can we better\neducate you on uncertainty\" but rather \"how can we convince you to go to\na therapist so you are better at understanding your own motivations\".\nRegardless I will address each argument I have come across even though my heart isn't in it.\n\n### Expertise\n#### Reason\nSome interviewees claimed that the uncertainty would add little to the plot because the audience knew that the author would only present statistically significant findings and the audience trusts their expertise.One participant in Hullman's study said \"Most people will trust the doctor, not necessarily because the information itself was trustworthy, but because the doctor was.\" when referencing why a certain level of expertise allows one to omit uncertainty [@Hullman2020a].\n\n#### Rebuttal\nI personally wish my doctor would give me probabilities and I have spent hours complaining to friends about the ones that don't. To make decisions about risk that *others* are taking on because *you* are an expert is wildly infantilising. I broke my finger when my usual GP was on leave and had to see someone else who said it was \"probably nothing to worry about\" and sent me home without an x-ray. I wish he had communicated the amount of uncertainty about that because I had to get a \\$5000 hand surgery 3 months later to correct his mistake. Because the\nuncertainty about his decision and the costs associated with an\nincorrect decision was not communicated to me, I took on a much higher risk than I was comfortable with. Significance is arbitrary, and communicating uncertainty around that value is necessary for the people making the decisions. This is just an anecdote but there is evidence that general audiences feel the same.\n\nThis excuse is similar to the \"complicates decision making\" reasoning in that the goal is to take on a god like position that not only calculates the statistical risk, but then decides how much of that risk the stakeholders are willing to take on. Any trustworthiness is artificially created through obfuscation of facts.  \n\n### Trust with the Audience\n#### Reason\nCommunicating uncertainty will result in people trusting our results less rather than more.\n  \n#### Rebuttal\nThis just isn't true. Hullman herself points out in her paper that there was a strange consensus that the participants seemed to think trust was a precursor to displaying uncertainty and not the other way around. I personally suspect people would trust visualisations that express uncertainty more than those that didn't (and I'm sure there are some papers out there on this that I can't be bothered to find right now) however I also haven't seen any evidence to the contrary.\n\nAdditionally, this reasoning seems to also be used to hide a more sinister motivation. Multiple participants from Hullman's study seemed to equate \"trust\" with \"not being questioned\" two statements that only a total egomaniac would think are equivalent. Many believed that you could only visualise uncertainty after you had established trust with the audience, stating that if you visualise your uncertainty prior to that \"someone will inevitably ask, 'how did you get these numbers?'\". A question I would argue is completely reasonable and justified. I just thing that if you commit fraud in response to your colleagues asking you reasonable questions, your fix is a personality one.\n\n### Fraud\n#### Reason\nI am not visualising uncertainty on purpose to misrepresent findings. Hullman's paper quotes an interviewee justifying not showing uncertainty in their visualisations because it hid the signal since the \"data wasn't reliable and uncertainty seemed too big\".\n  \n#### Rebuttal\nI have literally been asked to commit fraud in interviews, and when I pointed out to the interviewer that they were asking their new employee to commit fraud, I did not get a call back. I don't know how else you could describe \"playing with the numbers until you find one that looks good and showing those\", but apparently they felt like \"fraud\" was not fitting. \n\nIn statistics the truth is already blurry, that is the whole point of the field. What people don't seem to understand is that the methods around statistics need to be pretty rigorous because the final result is slightly blurry. Even innocent selections at an initial stage can unknowingly introduce bias in the final results. The numbers are not ironclad, but highly sensitive to the choices made by the statistician, which is why avoidance of fraud should be a high priority. Going 2km over the speed limit when you are certain of your speed is one thing, going 2km over the speed limit when you have a pretty good reason to suspect your speedometer could already be out by 10km/hour is another. \n\nUltimately I am not sure how to reason with someone knowingly or unknowingly performing fraud. The issue could be a general issue of a lack of integrity in the community as a whole, and considering someone was willing to ask me to do fraud at the interview stage of a hiring process, I would not be surprised. In general I think the only way to handle cases of outright fraud is to try and incentivise honest and open displays of data. Not only within organisations, but within the data community as a whole. \n\n## Why do I think People Don't Visualise Uncertainty?\nI personally think all these excuses are an effort to use someone's incompetence (the audiences or their own) to justify not having to do something they don't want to do.\n\nThis does not mean everyone who doesn't visualise uncertainty is evil. Widespread issues like this are almost universally created by systematic problems and norms. But the rationale provided by the participants in these studies **reek** of back justification. Hullman herself notices this, claiming in her paper \n\n> \"It is worth noting that many authors seemed confident in stating rationales, as though they perceived them to be truths that do not require examples to demonstrate. It is possible that rationales for omission represent ingrained beliefs more than conclusions authors have drawn from concrete experiences attempting to convey uncertainty\" [@Hullman2020a]. \n\nI took this as a fancy academic way of saying \"I think these people are full of it and are making up random reasons to justify why their actions don't reflect their beliefs\". This is not to say I have a poor view of the participants in the study. I think they are normal people doing what people do. Rather, I think that discussing the results with an absence of acknowledgement of the human psychology that got us there is disingenuous in of itself. Authors are likely reacting to unstated norms in the field that are so accepted they don't even question themselves when they create a visualisation that doesn't include uncertainty.\n\nFrom personal experience visualisation as a whole seems to be generally looked down upon in science. There is a large focus on facts and much less of a focus on communications. I sometimes wonder if there is an effort to purposely make research harder to understand. I don't think I am entirely off the mark considering I have many memories of my undergraduate lecturers d gloating to students about high fail rates and difficulty of their course. Obviously there is a prestige to doing something so complicated others struggle to understand it. When you hear that the\nproof for the Poincare conjecture (the only millennium prize problem to be solved) could only be understood by experts meeting at a conference and understanding the work in groups over several days, it inspires an idea of godlike intelligence. Therefore, if something is hard to\nunderstand it is a more advanced idea, and you are smarter for knowing it. Of course, something can be hard to understand because it is poorly communicated, not only because it is difficult, but that seems to be\nlost on a few researchers. A man asking for directions to the train station in gibberish is also difficult to understand, but he is unlikely to stand in front of a multivariate calculus lecture and brag about still being lost.\n\nVery often, while reading papers, I am floored by how difficult some academics are to understand. The papers have become more comprehensive as I understood the field more, but even so, many papers still leave me confused. If the research put out by academia is so difficult to comprehend it is even inaccessible to the people in it, I wonder what the point of our research is.  \n\n<center>![This is your brain on academic research](academicbrain.jpeg)</center>\n\nI want to clarify that I don't think people are avoiding visualising uncertainty because its more prestigious to avoid doing it. However, I do think visualising uncertainty, and visualisation as a whole have\nbecome caught up in the scientific quest for prestige through gatekeeping the field with poor communication.\n\nThere is a common theme in Hullman's paper of authors seeing uncertainty as a chip in their armour, a possibility to expose something they don't know and they hide it. Authors don't think audiences can understand uncertainty, so they make it completely inaccessible. Authors are afraid they don't know how to compute uncertainty, so instead of doing it badly, they ignore it. Authors are afraid of being questioned when they show the uncertainty, so they hide it. There are a lot of field wide issues that seem to be coming into play when authors are choosing not to visualise uncertainty and it becomes impossible to pin down a single reason. Authors don't have to give me their honesty, but they do need to give it to themselves, so the next time you sit down to make a visualisation, be honest with yourself about why you are ignoring the uncertainty. \n\n# References\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}