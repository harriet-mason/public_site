{
  "hash": "c0d7e3146ed067e06932118435696e29",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ETC3250: Tutorial 5 Help Sheet\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Question 1: Logistic Regression\n### Part A\nFit a logistic regression model to the training set. \n\n(No hint, the code is in the tutorial)\n\n### Part B\nCompute the confusion matrices for training and test sets, and thus the error for the test set. You can use this code to make the predictions.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Where to go for information\nYou have computed a confusion matrix multiple times before. Check lecture 4 [slide 15](https://iml.numbat.space/week4/slides.html#/check-the-model-performance) for an example of using a model to get the confusion matrix for the logistic model. \n:::\n\n### Part C\nThis question is an exploratory question so there isnt really a right or wrong question. Do think about it though.\n\n\n\n## Question 2: LDA\n### Part A\nIs the assumption of equal variance-covariance reasonable to make for this data? \n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Where to go for information\nCheck lecture 4 [slide 18](https://iml.numbat.space/week4/slides.html#/linear-discriminant-analysis) and [slides 40 to 43 ](https://iml.numbat.space/week4/slides.html#/checking-the-assumptions-for-lda-and-qda-12). \n:::\n\n\n### Part B\nFit the LDA model to the training data\n\n(No hint, the code is provided)\n\n### Part C\nCompute the confusion matrices for training and test sets, and thus the error for the test set. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Where to go for information\nYou have computed a confusion matrix multiple times before. Check lecture 4 [slide 15](https://iml.numbat.space/week4/slides.html#/check-the-model-performance) for an example of using a model to get the confusion matrix for the logistic model. Think about how to get the predicted class for a LDA model.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Extra code hint\nYou should use the `predict(lda_fit$fit, p_tr)$class` should give you the predicted class for an LDA model. You will need to do this twice, once on your training and once on your test set.\n:::\n\n### Part D\nUse boxplots and a tour to examine your fitted LDA model and see how it differs from your Logistic regression model. You can use this code to make the predictions.\n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Where to go for information\nCheck lecture 4 [slides 6 to 9 ](https://iml.numbat.space/week4/slides.html#/the-logistic-function) for an understanding on how logistic regression works, check lecture 4 [slides 18 to 22](https://iml.numbat.space/week4/slides.html#/linear-discriminant-analysis) to understand how LDA works. The answer is in the theoretical working of these two models.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Extra hint\nThink about the dimensional of this problem. You are looking at the data in 2D space. What dimension is the model rule drawn in?\n:::\n\n\n### Part E\nRe-do the plot of the discriminant space, to examine the boundary between groups. You'll need to generate a set of random points in the domain of the data, predict their class, and projection into the discriminant space. The `explore()` in the `classifly` package can help you generate the box of random points.\n\n#### Hint: Extra code hint\nYou should use the `explore(lda_fit$fit, p_tidy_std)` to generate the data and get predictions for those values. Once you have the predictions you should plot them.\n:::\n\n### Part F\nWhat happens to the boundary, if you change the prior probabilities? And why does this happen? Change the prior probabilities to be 1.999/3, 0.001/3, 1/3 for Adelie, Chinstrap, Gentoo, respectively. Re-do the plot of the boundaries in the discriminant space. \n\n::: {.callout-tip collapse=\"true\"}\n#### Hint: Where to go for information\nCheck lecture 4 slide [27](https://iml.numbat.space/week4/slides.html#/example-penguins-13) for a hint on how to change the prior for probability for the code. Describe what happens think about why.\n:::\n\n\n## Question 3: Misclassifications\nThis question is an exploratory question so there isnt really a right or wrong question.\n\n## Question 4: Math\nIt is hard to explain what is happening without giving away the logic to solve the question. If you want me to go through this question, please let me know and we can go through it as a class in the last 20 mins.\n",
    "supporting": [
      "etc3250tutorial5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}