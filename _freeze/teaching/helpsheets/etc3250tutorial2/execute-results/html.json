{
  "hash": "bae1a67f9cff9adf490acef9a42b2ad0",
  "result": {
    "markdown": "---\ntitle: \"ETC3250: Tutorial 2 Help Sheet\"\n---\n\n::: {.cell}\n\n:::\n\n\n# Flux\nJoin this weeks flux using [this link](https://flux.qa/V3UHTY)\n\n# Exercises\n## Question 1\n### Part A to E\na. What is $X_1$ (variable 1)?\nb. What is observation 3?\nc. What is $n$?\nd. What is $p$?\ne. What is $X^\\top$?\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [week 1 lecture slides 13 to 18](https://iml.numbat.space/week1/slides.html#/data-math) \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nThe notation section of the [matricies wiki page](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Notation) might also help. The wiki page should also have a definition of the [transpose](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Basic_operations). \n:::\n\n### Part F\nf. Write a projection matrix which would generate a 2D projection where the first data projection has variables 1 and 4 combined equally, and the second data projection has one third of variable 2 and two thirds of 5.\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [week 1 lecture slides 19 to 24](https://iml.numbat.space/week1/slides.html#/linear-algebra) \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nI would reccomend checking [this](https://dicook.github.io/mulgar_book/2-notation.html) page of the Cook and Laa textbook for the requirements of a projection matrix. Remember, matricies are just a simple way to describe a system of linear equations. \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 3\nI would suggest writing the matrix that combines the variables correctly and *then* make sure it follows the gneeral requirements for a projection matrix. The projected data ($Y$) should have dimension 1 equally variable 1 and variable 4, that is to say $Y_1 = \\frac1 2 X_1 + \\frac1 2 X_4$ and dimension 2 should be a third variable 2 and two thirds variable 5, that is $Y_2 = \\frac1 3 X_2 + \\frac 2 3 X_5$. Write these equations in matrix form to get a starting point for your answer. \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 4\n\nThe matrix equation that represents that linear system above is:\n\n\\begin{align*}\n{\\mathbf Y = \\mathbf{XA}} = \n\\left[\\begin{array}{rrrrr} \n2 & -2 & -8 & 6 & -7 \\\\\n6 & 6 & -4 & 9 & 6 \\\\\n5 & 4 & 3 & -7 & 8 \\\\\n1 & -7 & 6 & 7 & -1\n\\end{array}\\right]\n\\left[\\begin{array}{rr} \n1/2 & 0 \\\\ \n0 & 1/3  \\\\\n0 & 0 \\\\\n1/2 & 0 \\\\\n0 & 2/3 \\\\\n\\end{array}\\right] \n\\end{align*}\n\nThis matrix has not been adjusted to fulfill the requirements of a projection matrix. If you are unsure how to convert this into a projection matrix, check the hints for Part G.\n:::\n\n### Part G\ng. Why can't the following matrix considered a projection matrix?\n\n\\begin{align*}\n{\\mathbf A} = \\left[\\begin{array}{rr} \n-1/\\sqrt{2} & 1/\\sqrt{3} \\\\ \n0 & 0  \\\\\n1/\\sqrt{2} & 0 \\\\\n0 & \\sqrt{2}/\\sqrt{3} \\\\\n\\end{array}\\right]\n\\end{align*}\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\n**(same as Hint 1 Part F)**\nCheck [week 1 lecture slides 19 to 24](https://iml.numbat.space/week1/slides.html#/linear-algebra) \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\n**(same as Hint 2 Part F)**\nI would recommend checking [this](https://dicook.github.io/mulgar_book/2-notation.html) page of the Cook and Laa textbook for the requirements of a projection matrix. Remember, matricies are just a simple way to describe a system of linear equations.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 3\nThe requirements for any projection matrix are:\n1) The projected data should be a 2D matrix with n observations. Therefore the projection matrix has a specific dimensionality according to the rules of matrix multiplication which can be found [on the wiki page](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Basic_operations).  \n2) The projection matrix should be orthonormal which means each column should be [orthonomal](https://en.wikipedia.org/wiki/Orthonormality) with the other columns in the matrix. Remember, a vector cannot be orthogonal to itself.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 4\nThe requirements for any projection matrix are (more specifically):\n1) Since the data is $n \\times p$  and the projected data needs to be needs to be $n \\times p$ the projection matrix should have the dimension $p \\times d$. In this case, $d=2$\n2) Since $d=2$ you only need to check each column is normalised (this will be two calculations) and the two columns are orthogonal to each other (this is just one calculation). A vector is normalised if it has a length of 1, i.e. $\\sqrt{a_{11}^2 + a_{12}^2 + ... + a_{1n}^2}=1$. Two vectors are orthogonal to each other if their dot product is 0. That is, for columns i and j (where $i \\neq j$) they need to satisfy: \n$$a_i \\cdot a_j = \\sum_k^n(a_{ik} \\times a_{jk}) = 0 $$\nIf you are unfamiliar with summation notation, this is just:\n$$(a_{i1} \\times a_{j1}) + (a_{i2} \\times a_{j2}) + ... + (a_{in} \\times a_{jn}) = 0$$\n:::\n\n## Question 2\nWhich of these statements is the most accurate? And which is the most precise?\n\n*A. It is almost certain to rain in the next week.*\n\n*B. It is 90% likely to get at least 10mm of rain tomorrow.*\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [week 1 lecture slide 26](https://iml.numbat.space/week1/slides.html#/accuracy-vs-interpretability) to see a diagram that depicts the difference between accuracy and precision\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nAccuracy tells you how likely a statement is to be true, and precision tells you how specific a statement is. For example, if I guess your weight to be somewhere between 0 and 1000kg, my statement is highly accurate (true with 100% certainty) but imprecise to the point of being meaningless. Typically a more accurate statement will be less precise, and a more precise statement will be less accurate.\n:::\n\n## Question 3\nFor the following data, make an appropriate training test split of 60:40. The response variable is cause. Demonstrate that you have made an appropriate split.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(rsample)\n\nbushfires <- read_csv(\"https://raw.githubusercontent.com/dicook/mulgar_book/pdf/data/bushfires_2019-2020.csv\")\nbushfires |> count(cause)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n  cause           n\n  <chr>       <int>\n1 accident      138\n2 arson          37\n3 burning_off     9\n4 lightning     838\n```\n:::\n:::\n\n\n::: {.callout-note}\n## Harriet's Comment\nIf you want to get the same results as the solution (and the flux quiz) use `set.seed(1156)`\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [week 1 lecture slides 27 and 28](https://iml.numbat.space/week1/slides.html#/training-vs-test-splits). \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nCheck the function `initial_split` with `?initial_split`. Also look at the functions `training` and `count` to check your split and see how many are in each group.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 3\nYour function should use the options `initial_split(data, prop=??, strata=??)` to set an initial split. Then using `testing(split) |> count(same variable you used for strata)` to check the correct amount is in each group.\n:::\n\n## Question 4\nIn the lecture slides from week 1 on bias vs variance, these four images were shown.\n\n(the images are in the tutorial, I'm not going to move them here)\n\nMark the images with the labels “true model”, “fitted model”, “bias”. Then explain in your own words why the different model shown in each has (potentially) large bias or small bias, and small variance or large variance.\n\n::: {.callout-note}\n## Harriet's Comment\nThe data in the images is *testing* data, so the model was not trained on it. Additionally, there is no error in the data generating process, that is to say, generated data is perfectly categorised according to the true model. Keep this in mind when considering the source of the error.\n\nChapter 2 of the ISLR textbook is of *particular* use for questions that require an understanding of the bias/variance trade off, such as this one.\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [week 1 lecture slides 33 to 42](https://iml.numbat.space/week1/slides.html#/parametric-vs-non-parametric)\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nThe black line is the true boundary (that generates the data), the colored dots show what the model has predicted. There is no noise so the wave function should *perfectly* categorise the observations.\n\nLook for areas where there is error in the model (i.e. the coloured dots diverge from the from the true model) and try to work out what is causing them. Is the error bias, variance or irreducible? Try to explain if there is any common themes in the errors in the images.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 3\nThe black Bias is caused by an inflexible model, variance is caused by a model that is *too* flexible. Error from bias will be predictable and consistent sources of error, error from variance will be inconsistent and hard to differentiate from irreduciable error. Error from bias is always visible in the images, error from variance only exists in repeated samples, however you should still mention it if you have used a highly flexible model.\n:::\n\n## Question 5\nThe following data contains true class and predictive probabilities for a model fit. Answer the questions below for this data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_data <- read_csv(\"https://raw.githubusercontent.com/numbats/iml/master/data/pred_data.csv\") |>\n  mutate(true = factor(true))\n```\n:::\n\n\n### Part A\nHow many classes?\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nTry using `count()` or `table()` or a similar function you are familiar with.  \n:::\n\n### Part B\nCompute the confusion table, using the maximum predictive probability to label the observation.\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nYou have been given data that contains the true class, the probability an observation is class Adelie and the probability an observation is class Chinstrap. You need to make a new variable that represents the predicted class and add it to your data set. Then you need to use the predicted class and the true class to make a confusion matrix.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nFirst use `mutate()` to add the predicted class to your data frame\n\nThe theory and code used to make a confusion matrix from a data set with the true and predicted values is shown on [lecture 1 slides 30 to 31](https://iml.numbat.space/week1/slides.html#/confusion-misclassification-matrix). \n:::\n\n### Part C\nCompute the accuracy, and accuracy if all observations were classified as Adelie. Why is the accuracy almost as good when all observations are predicted to be the majority class?\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [lecture 1 slides 30 to 31](https://iml.numbat.space/week1/slides.html#/confusion-misclassification-matrix). It shows you how to calculate accuracy by hand and with code. \n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nTo calculate the accuracy if if all observations were classified as Adelie, you can either use the formula on slide 30, or add a new variable where all the predictions are Adelie and calculate it with the code on slide 31.\n:::\n\n### Part D\nCompute the balanced accuracy when all observations were classified as Adelie, by averaging the class errors. Why is it lower than the overall accuracy? Which is the better accuracy to use to reflect the ability to classify this data?\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nAgain, check [lecture 1 slides 30 to 31](https://iml.numbat.space/week1/slides.html#/confusion-misclassification-matrix). It shows you how to calculate the balaced accuracy by hand and with code. \n:::\n\n## Question 6\nThis question relates to feature engineering, creating better variables on which to build your model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\nspam <- read_csv(\"http://ggobi.org/book/data/spam.csv\")\nggplot(spam, aes(x=spam, y=size.kb, colour=spam)) +\n  geom_quasirandom() +\n  scale_color_brewer(\"\", palette = \"Dark2\") + \n  coord_flip() +\n  theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](etc3250tutorial2_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n### Part A\nThe following spam data has a heavily skewed distribution for the size of the email message. How would you transform this variable to better see differences between spam and ham emails?\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nCheck [lecture 1 slides 43](https://iml.numbat.space/week1/slides.html#/feature-engineering). You can replace the skewed variable with its transformed version, however it is better practice to leave your data as is and only transform it in the model (or in this case, in the visualisation).\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 2\nTry adding `scale_y_log10()` to the `ggplot` that generated the visual.\n:::\n\n### Part B\nFor the following data, how would you construct a new single variable which would capture the difference between the two classes using a linear model?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nolive <- read_csv(\"http://ggobi.org/book/data/olive.csv\") |>\n  dplyr::filter(region != 1) |>\n  dplyr::select(region, arachidic, linoleic) |>\n  mutate(region = factor(region))\nggplot(olive, aes(x=linoleic, \n                  y=arachidic, \n                  colour=region)) +\n  geom_point() +\n  scale_color_brewer(\"\", palette = \"Dark2\") + \n   theme(legend.position=\"none\", \n        aspect.ratio=1)\n```\n\n::: {.cell-output-display}\n![](etc3250tutorial2_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nStart by drawing a straight line that does a good job of separating the variables. Consider how you should make a new variable that will allow you to perfectly separate the data. Consider how you made a projection matrix in question 1.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint 1\nYour new variable should be perpendicular to the line that separated the variables. Once you have a function that represents that line, you can use it to make a new variable. .\n:::\n\nPlot your new variable to see if it does a good job of separating the values\n\n## Question 7\nDiscuss with your neighbour, what you found the most difficult part of last week’s content. Find some material (from resources or googling) together that gives alternative explanations that make it clearer.",
    "supporting": [
      "etc3250tutorial2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}