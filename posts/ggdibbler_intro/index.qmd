---
title: "You guys are going to SHIT your pants when you see this R package I cooked up"
author: "Harriet Mason"
editor: source
---

# TLDR
You can pass random variables to ggplot now. Any geom, any aesthetic (except groups and facets), they all accept random variables. I make no judgements on your plot, I am not your king. Whatever your plot is, `ggdibbler` will allow you to pass a random variable to it. You can read the documentation [here](https://harriet-mason.github.io/ggdibbler/). I know, you are amazed and impressed, and for that you are all WELCOME. And I will answer the one question you are dying to hear the answer to, I DO accept cash gifts sent directly to my bank account, thanks.

# The long version that makes you regret clicking on this blog post
## Gotta obey the tiny demon
I'm not really the kind of person who has "dicipline" or "tenacity". I only really stick to something if it is a source of spite for me. I have many many many enemies that do not even know I exist. My most common advice to everyone I know is "quit". Which may sound depressing, but I think it is just deeply related to my life philosophy of "you win no awards for suffering for the sake of suffering". I spend basically all my time doing exactly what I feel like. Which can sound relaxing, but unfortunately for me, "exactly what I feel like" is actually decided by a tiny DEMON who lives in my subconscious and is desperately trying to ruin my life.

Like, right now it is 6am and I really should be asleep, but instead I am writing this blog post and I have been doing some combination of that and working on my package for the past 6 hours. This isnt even urgent or necessary, I am still several weeks out from the completion of the package (and therefore the release of this blog post). But if I stop writing this blog post, I will be filled with immense discomfort as the tiny demon *always* punishes those that do not obey. There is no anxiety or stress or external validation or an angle and devil on my shoulder, there is only the tiny demon who compels me to do whatever it wants (this sounds like I am in the throws of a mental episode, but I promise you, I am not).

The tiny demon does not always want to work though, actually, often they do not. I am largely unbothered by this, but the people who sign my paychecks usually are not big fans of the whims of the tiny demon. I actually track all the hours I spend doing almost everything (this sounds neurotic and I promise, it is), so I have acutally made a chart of the number of hours I work each week. 

```{r}

```

I also sent this plot to my supervisors (we were discussing if TA work has a negative impact on the number of hours I spend doing research work). You might think it is a bad idea to send a chart that says I work 14 hours a week to my supervisors, but Di was far more concerned about my plot choice.



After finishing the first chapter of my thesis, the tiny demon lost interest in research and instead wanted to take up stained glass. I am not joking, here is the window I made of my dogs face.


Anyways, this is all to say, my work rate for most of the life of this package was pretty low. I was chipping away at bits here and there, but I wasn't completely statisfied with the solution to uncertainty visualisation I had.

## An overview of my uncertainty visualisation philosophy
Gather around children, let me tell you the view of uncertainty visualisation that led to my excellent package. The long version of the approach (I actually think it is a good read) is written up in the paper that was the first chapter of my PhD thesis, you can read it [here](https://arxiv.org/abs/2411.10482). A shorter version of it was given as a talk at UseR!. A slightly longer but less professional version is given here.

Exactly "what" uncertainty visualisation is, seems to be hard to pin down. There are two competing philosophies of uncertainty visualisation. They are:
(1) Uncertainty visualisation is any visualisation of an uncertainty statistic. This can be a variance, error, density function, probability, standard error, etc.
(2) Uncertainty visualisations are a function of an existing graphic, where uncertainty is integrated into the plot in such a way that it prevents us from taking away false or misleading signals.
Now, given the history of statistical graphics, (1) feels obviously wrong to me. Nowhere else do we define a plot by its underlying statistics. Otherwise, we should have central tendancy and exteme value plots. We do not, because we do not, and never have, defined plots this way. This leaves (2) which I think is a far more interesting question. 

This philosophy means that uncertainty visualisation are functions of plots, rather than an innate quality a plot can have in a vaccume. Plots can only be "uncertainty" visualisations in relation to a plot that was somehow absent uncertainty. I ended up calling this goal (and the function that creates an uncertainty visualisation) "signal supression" in reference to one of the few papers that seemed to consistently apply the "uncertainty visualisation as a function" philosophy, [Value Supressing Uncertainty Palettes](https://dl.acm.org/doi/10.1145/3173574.3174216). The only reason we didn't call it value supression, is because we are not specifically supressing individual values, we are trying to supress the "plot level" take away.

This "uncertainty visualisation as a function" approach also means there should be an uncertainty version of data. The obvious answer is that the uncertainty version of data is just random variables. But, you cant store random variables in a tibble, which you would need to do to be able to feed them to ggplot. So I'm thinking, oh god do I have to make some kind of random variable vector object thing? And thankfully, the answer was no.

Praise be unto the gods of open source software, someone else already did it. From what I can gather, it seems that Mitch and Rob wanted distribution vectors for forecast outputs (and Mitch's graph, distribution, time, space magnum opus he is working on that I think is related to Cynthia's work as well? but do not understand and I am not going to pretend I do, I am just over here making plots please don't make me think about data types) and Matthew Kay and Alex Hayes also wanted a distribution object for THEIR uncertainty visualisation work (the distribution objects are also utilised by `ggdist`). So, Mitch, Rob, Matt and Alex have my utmost appreciation for making an object I desperately needed, about 5 years before I needed it.

As an aside, what I think is the most interesting thing about Matt's work is that the data type suggests the signal suppression approach, but then the graphics made by `ggdist` suggest the "uncertainty is a function of a distribution" approach. His papers jump between the two philosophies. I actually think he does both of them well ([This paper with a title too long to type out](https://osf.io/preprints/osf/6xcnw_v1) is genuinely one of my favourites) but obviously I am partial to the signal-suppression papers. I genuinely cannot work out his internal definition of an uncertainty visualisation. Based on a conversation with him, it seems to be a kind of holistic decision making thing that is depends largely on the task the plot is used for (which is quite a typical belief in computer science). Similarly to Mitch's mega-datastructure-magnum-opus, I do not understand and I am choosing to not think about it that much.


So before I was going to make a package that allows you to have a random variable object type, I am going to check it doesn't already exist. Thank god for open source software, because my version of `distributional` would have been dogshit. I didn't have to do this part. 


Graphics relativity or soemthing, I don't know.

every visualisation has an uncertaintyHow do you integrate uncertainty into a 

For an uncertainty visualisation to successfully perform signal supression, visual patterns should be easily recognised when the uncertainty is low, and hard to see when the uncertainty is high. The statistical validity should translate to perceptual ease. 

## Don't give your plot a name, I am not using it and I have already forgotten it.
For the love of god, Leeland Wilkinson wrote the grammar of graphics 25 years ago, and was all "STOP GIVING ALL YOUR PLOTS BESPOKE NAMES". So what does everyone do? Continue to give all their plots bespoke names and then demand I use it. I feel like I live in a crazy town where there are thousands of visualisation researchers who write ggplot extensions and not a single one has ever cracked open the Grammar of Graphics textbook. Leeland is out here on the first page begging you to stop using graph names. Not only do named graphs go against the grammar of graphics philosophy, but they also lead to peacemeal solutions and do not encourage any deeper search for uncerstanding of what we are trying to visualise.

I find piecemeal solutions incredibly annoying. Solutions should be *elegant* and give me a new-found appreciation for the theory of a field. I should get a shiver down my spine as I think "wow I never would have thought of this in a million years". Like how every Maths student hears the story about Guass coming up with the formula for a sum of an arthmetic series and immediately has a deep sensation that they doomed to spend eternity as a dumb little guy who is just rolling in the mud by comparison. 

Piecemeal solutions make me feel as though I am just memorising a bunch of facts rather than learning how they work, and I simply don't care about anything enough to suffer through that. I don't like them for the same reason I cannot spell and I don't read the news (why is it different all the time? just have like 5 axioms of human behaviour or something and call it a day). The main way you interact with news and spelling is just learning every individual piece and then you just... what? Memorise all this random garbage?? Absolutely not. Just kill me. I would rather die. 


Me standing in the PhD room, saying (angrily yelling is more accurate) to Jayani "Oh can I just make this in ggplot, if I make this in ggplot and give it a name, is it my plot now?? I own this plot??? BRB everyone I'm going to go copyright the NUMBER 64345" was a frequent enough occurence that I may have acutally caused a bit of detrimental impact on her PhD (sorry Jayani).

Like, lets look at one particular case. Visualisation distributions, especially when done with a sample, requires you to fix overplotting. 
- Pixel map
- Hops plot

Integration over a different variable
- ggdibbler vs ggdist
- 







In the same way I don't

I don't consciously come to them, its more like they attack me in the middle of the night and I just have to go

One of the most important components of the ggdibbler solution to uncertainty visualisation genuinely occured this way. I didn't originally plan to apply to package to *every* plot (only the plots that used `stat_identity`) because some plots are run through a statistic (e.g. geom_density) and I had no idea if it was even meaningful to HAVE an uncertainty visualisation of a density plot. This was something I said during my *UseR! 2025* talk, and basically had that opinion until about six weeks ago. Six weeks ago I woke up at 5am (very unusual for me, I'm more of a 10am riser), and at the TOP of my mind was the thought "You could apply signal supression to any plot if you group by the draw number". So I immediately opened my laptop and implemented it, and it worked. 

I could hardly call this solution "something I arrived at by conscious thought". Do I know where that came from? No. Did I consciously think of it? No. Like most things in my life, it was a gift (or a curse) given to me by a tiny demon that 

